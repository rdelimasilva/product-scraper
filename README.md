# Web Scraper Supabase

AutomaÃ§Ã£o para extrair dados de produtos do site Casoca e salvar no Supabase.

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ src/                      # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ index.js             # Arquivo principal de entrada
â”‚   â””â”€â”€ scrapers/            # ImplementaÃ§Ãµes dos scrapers
â”‚       â”œâ”€â”€ production/      # Scrapers prontos para produÃ§Ã£o
â”‚       â”‚   â”œâ”€â”€ production-scraper.js
â”‚       â”‚   â”œâ”€â”€ professional-scraper-api.js
â”‚       â”‚   â”œâ”€â”€ scraper-final-production.js
â”‚       â”‚   â””â”€â”€ working-scraper.js
â”‚       â””â”€â”€ development/     # Scrapers experimentais/desenvolvimento
â”‚           â”œâ”€â”€ scraper-*.js
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/                 # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ analysis/           # Scripts de anÃ¡lise do site
â”‚   â”‚   â”œâ”€â”€ analyze-*.js
â”‚   â”‚   â””â”€â”€ investigate-real-links.js
â”‚   â”œâ”€â”€ database/           # Scripts de banco de dados
â”‚   â”‚   â”œâ”€â”€ *.sql
â”‚   â”‚   â”œâ”€â”€ supabase-setup.js
â”‚   â”‚   â”œâ”€â”€ create-test-records.js
â”‚   â”‚   â””â”€â”€ remove-duplicates*.js
â”‚   â”œâ”€â”€ deployment/         # Scripts de deploy
â”‚   â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”‚   â””â”€â”€ deploy-hetzner.sh
â”‚   â”œâ”€â”€ debug-*.js         # Scripts de debug
â”‚   â”œâ”€â”€ check-products.js   # VerificaÃ§Ã£o de produtos
â”‚   â”œâ”€â”€ estimate-scraping-time.js
â”‚   â”œâ”€â”€ quick-test.js
â”‚   â”œâ”€â”€ run-scraper.js
â”‚   â””â”€â”€ simple-5-products.js
â”‚
â”œâ”€â”€ tests/                  # Testes e arquivos de teste
â”‚   â”œâ”€â”€ test-*.js
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ config/                 # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ ecosystem.config.js # ConfiguraÃ§Ã£o do PM2
â”‚   â””â”€â”€ category-targets.json (se existir)
â”‚
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ DEPLOYMENT-GUIDE.md
â”‚   â”œâ”€â”€ PROXY_SETUP.md
â”‚   â””â”€â”€ test-real-browser.md
â”‚
â”œâ”€â”€ assets/                 # Recursos e arquivos estÃ¡ticos
â”‚   â”œâ”€â”€ *.png              # Imagens de anÃ¡lise
â”‚   â””â”€â”€ *.html             # Arquivos HTML de teste
â”‚
â”œâ”€â”€ logs/                   # Arquivos de log
â”‚   â”œâ”€â”€ *.log
â”‚   â””â”€â”€ *.json
â”‚
â”œâ”€â”€ .env                    # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore             # Arquivos ignorados pelo Git
â”œâ”€â”€ package.json           # DependÃªncias do projeto
â””â”€â”€ package-lock.json      # Lock das dependÃªncias
```

## ğŸš€ Como Usar

### InstalaÃ§Ã£o
```bash
npm install
```

### Executar o scraper principal
```bash
npm start
```

### Modo de desenvolvimento (com watch)
```bash
npm run dev
```

### Executar em produÃ§Ã£o com PM2
```bash
pm2 start config/ecosystem.config.js
```

## ğŸ“‚ CategorizaÃ§Ã£o dos Arquivos

### ğŸ”§ **src/scrapers/production/**
Scrapers testados e prontos para uso em produÃ§Ã£o:
- `production-scraper.js` - Scraper principal para produÃ§Ã£o
- `professional-scraper-api.js` - VersÃ£o profissional usando API
- `working-scraper.js` - VersÃ£o funcional estÃ¡vel

### ğŸ§ª **src/scrapers/development/**
Scrapers experimentais e versÃµes de desenvolvimento com diferentes abordagens e features.

### ğŸ“Š **scripts/analysis/**
Scripts para anÃ¡lise e investigaÃ§Ã£o do site alvo:
- AnÃ¡lise de filtros, produtos, navegaÃ§Ã£o
- InvestigaÃ§Ã£o de links e estrutura do site
- Estimativas de tempo de scraping

### ğŸ—„ï¸ **scripts/database/**
Scripts relacionados ao banco de dados:
- Setup do Supabase
- Limpeza e remoÃ§Ã£o de duplicatas
- CriaÃ§Ã£o de registros de teste
- Queries SQL

### ğŸ§ª **tests/**
Testes diversos incluindo:
- Testes de conectividade
- Testes de bypass do Cloudflare
- Testes de proxy
- Testes de API

### âš™ï¸ **config/**
Arquivos de configuraÃ§Ã£o do projeto:
- ConfiguraÃ§Ã£o do PM2 para produÃ§Ã£o
- Targets de categorias (se aplicÃ¡vel)

## ğŸ”§ Tecnologias Utilizadas

- **Node.js** - Runtime JavaScript
- **Puppeteer** - AutomaÃ§Ã£o de browser
- **Supabase** - Banco de dados e storage
- **PM2** - Process manager para produÃ§Ã£o
- **ScraperAPI** - API para contornar limitaÃ§Ãµes

## ğŸ“ Logs

Os logs sÃ£o salvos na pasta `logs/` com diferentes nÃ­veis:
- Logs de erro
- Logs combinados
- Logs especÃ­ficos do PM2

## ğŸš€ Deploy

Consulte a documentaÃ§Ã£o em `docs/DEPLOYMENT-GUIDE.md` para instruÃ§Ãµes detalhadas de deploy.

## ğŸ”’ ConfiguraÃ§Ã£o

1. Copie `.env.example` para `.env`
2. Configure as variÃ¡veis de ambiente necessÃ¡rias:
   - `SUPABASE_URL`
   - `SUPABASE_ANON_KEY`
   - `SCRAPER_API_KEY` (se usar ScraperAPI)

## ğŸ“– DocumentaÃ§Ã£o Adicional

- `docs/PROXY_SETUP.md` - ConfiguraÃ§Ã£o de proxy
- `docs/test-real-browser.md` - Testes com browser real
